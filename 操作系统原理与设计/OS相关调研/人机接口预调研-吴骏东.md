## 1.往届人机接口相关项目

### 2018 X-oalad

- 小组成员：邓龙 戴路 吴紫薇 徐煜森 于颖奇
- 项目简介：本项目旨在建立一个低成本的新方式，利用简单的头戴设备或者桌面设备（包括设备自带设备，如摄像头），对用户的视线信息做出分析，提取出有效信息作为机器输入，从而作为一种新的机器控制方法。具体地说，希望能从用户眼部信息中，实时的定位用户关注的屏幕区域、进行注视检测、提供辅助阅读等功能。
- 关键词：可穿戴设备，图像处理
- 注：该课题方向在历年中较为少见



## 2.其他调研

### 眼球跟踪的常见方法

在眼跟踪技术发展过程中，许多科学家不断地研究、探索，创造性地提出了些跟踪眼睛运动的方法。从一开始的直接观察法、机械记录法到后来的电磁感应法、电流记录法及接触镜法、角膜反射跟踪法、双普金野法、虹膜——巩膜边缘跟踪技术、瞳孔——角膜跟踪法等。其具体原理如下：

1. 电磁感应法：将被试的眼睛麻醉，把一个装有探察线圈的隐形镜片吸附在眼睛上。线圈中存在感应电压，通过对感应电压的相敏检测，可以精确地测量水平和垂直方向的眼动。这种方法精确度高，但是接触眼球会引起受试者的不适。
2. 电流记录法：眼球运动可以产生生物电现象。角膜和视网膜的新陈代谢是不一样的，角膜部位的代谢率较小，网膜部位的代谢率较大，所以角膜和网膜之间就形成了电位差，角膜带正电，网膜带负电。当眼睛注视前方未发生眼动时，可以记录到稳定的基准电位， 当眼睛在水平方向上运动时，眼睛左侧和右侧的皮肤之间的电位差会发生变化， 而当眼睛在垂直方向上运动时，眼睛上侧和下侧的电位差会发生变化。将两对氯化银皮肤表面电极分别置于眼睛左右、上下两侧，就能引起眼球变化方向上的微弱电信号，经放大后得到眼球运动的位置信息。这种方法的特点是高宽带、低精度、对人干扰大。
3. 接触镜法：首先将一个小镜子附着在被试眼睛上，光线射向镜子，被反射的光线随着眼球的运动而变化，从而获得眼动信号。其技术特点是精度最高、高带宽、对人干扰大，使人有不舒适的感觉。
4. 角膜反射跟踪法：因为角膜是从眼球体的表面凸出来的，所以在眼球运动过程中，角膜对来自固定光源的光的反射角度也是变化的，因此可以在人眼前方放置一个近红外LED光源，和一个固定在受试者头部正前方的相机，角膜反射的光线通过眼睛前面的光束分离设备和一些反射镜、透镜传输到相机。同样的装置设于另一只眼睛前方。角膜反射光线的位置通过固定在头前方的摄像机屏幕上的图像及相应的一些算法来确定。该系统最大的误差主要是头部光学系统的滑动和由于眼睛与照相机镜头之间的距离而引起的误差。
5. 双普金野法：普金野图像是由眼睛的若干光学界面反射所形成的图像。角膜所反射出来的图像是第一普金野图像，从角膜后表面反射出来的图像微弱些，称为第二普金野图像，从晶状体前表面反射出来的图像称为第三普金野图像，由晶状体后表面反射出来的图像称为第四普金野图像。通过对两个普金野图像的测量可以确定眼注视位置。其技术特点是高精度、高带宽、对人干扰大。
6. 虹膜、巩膜边缘跟踪技术：用不可见的红外光照射眼部，在眼部附近安装两只红外光敏管，是虹膜与巩膜的边缘处的左右两部分反射的红外光分别为这两只光敏管所接受。当眼球向右运动时，虹膜转向右边，右边的光敏管所接受的红外线就会减少；而左边的巩膜反射部分增加，导致左边的光敏管所接受的红外线增加。利用这个差分信号就能无接触的测出眼动。其缺点是误差大，垂直精度低。
7. 瞳孔、角膜跟踪法：系统光学元件在空间固定，相对受试者的眼睛有较为固定的距离，并将反射的图像用摄像机记录下来，将摄像机获得的数据通过计算机或微处理器处理，辨别瞳孔和CR(角膜)，然后把角膜反射点数据作为眼摄像机和眼球的相对位置的基点，根据瞳孔中心位置坐标计算出在屏幕空间中的凝视点。这种方法准确、头具误差小且对人无干扰[7,10]。基于Hough变换圆检测法需要在参数空间内对3个参数圆心、半径等进行搜索。首先用积分投影法检测到眼睛瞳孔的大致位置，然后用边缘检测算子提取图像边缘信息，并将边缘图像二值化，然后再利用基于圆的Hough变换快速定位出人眼。



### **人机交互中眼动跟踪技术的局限性**

由于眼动跟踪技术还不成熟，不同的眼动跟踪技术有其各自的优缺点，例如采样率、精确度及干扰性等，因此目前将其应用于人机交互中还存在着一定的局限性，主要有精度与自由度的问题、“米达斯接触”问题以及算法问题。

首先是精度与自由度的问题。以硬件为基础的视线跟踪技术与以软件为基础的视线跟踪技术相比，其精度较高，但由于使用的设备限制了人的自由度，所以对人有较大的干扰，使用起来不是很方便；以软件为基础的视线跟踪技术，虽然降低了对用户的限制，但其精度相对而言低得多，要想得到准确的注视焦点比较困难。精度与自由度目前是一对尖锐的矛盾。

其次是“米达斯接触”问题。用户视线的移动往往是随意的，并不总有一定的意义，移动视线不代表就要发出一条计算机命令。因此如果屏幕上的计算机鼠标指针总是随着用户的视线移动，很可能会引起用户的厌烦。如果能够在用户希望发出控制时，界面及时的处理用户的视线输入，而相反时则忽略视线的移动，则可以很好的解决这个问题。遗憾的是，一般无法区分这两种情况。

再次是算法问题。眼动中的抖动、眨眼易造成数据中断，这种干扰信号，使得获取注视焦点的屏幕投影以及眼动数据都存在一定的困难。对于第一个问题，可以把离注视点最近的屏幕对象作为用户感兴趣的对象，但由于注视点本身的精度较低，当屏幕元素离得较近时则难以判断；对于后一个问题，目前是尝试使用眼动的某种先验模型来加以弥补。但是目前还没有能够把视觉通道与其它通道整合，实现无缝连接的成熟、高效的融合方法。文中对于眨眼的情况，在瞳孔轮廓特征点的探测部分予以考虑，利用设置门限的方法进行判别，一旦超过门限值，便认为产生了数据中断，则开始下一帧图像的处理。



### **基于神经网络的眼动跟踪技术发展前景**

近年来，由于深度学习的发展，基于神经网络的眼动跟踪技术也有了发展。有研究表明高效的眼动跟踪软件可以可靠地工作在智能手机和平板电脑等移动设备,而不需要任何外部附件。使用移动设备进行眼动追踪技术能提供许多好处:

- (1)广泛使用更多的超过三分之一的世界人口估计智能手机在2019年,远远超过台式机或笔记本用户的数量;
- (2)技术升级的采用率高——很大一部分人拥有最新的硬件，可以实时使用计算成本高昂的方法，如卷积神经网络(CNNs);
- (3)移动设备上相机的大量使用导致相机技术的快速发展和部署；
- (4)相机相对于屏幕的固定位置减少了未知参数的数量。

![img](C:\Users\Huawei\Desktop\OS相关调研\pictures\eyetracking_1.png)

视点估计又被分为基于模型的或者基于外观的，基于模型的方法根据几何模型又被分为基于角膜反射和基于形状的方法，角膜反射的方法通过外部光源检测眼睛特征，基于形状的通过眼睛的方法shape推测出视点方向（例如瞳孔中心或者虹膜边缘）。该论文中，作者的眼动追踪CNN。输入包括左眼,右眼,脸的原始帧图像检测。输出是距离相机的距离，单位是厘米。



### 一个利用OpenCV实现眼球状态判断的例子

[opencv眼动识别 - 古月居 (guyuehome.com)](https://guyuehome.com/34298)

//不过感觉这里重心就有点偏离OS了...



### 眼球中心定位算法Eyelike

[眼球中心定位跟踪算法—eyelike_zhangxu-CSDN博客_眼球跟踪](https://blog.csdn.net/chaipp0607/article/details/79935302)

该项目从网络摄像头读取视频，进行人脸检测，再根据检测到的人脸图像截取左眼和右眼的ROI区域，最后根据截取到的ROI进行眼球中心检测与跟踪。所以算法的主要包含三个部分：人脸检测，ROI截取，眼球中心定位。



### 市场上的成品

[Tobii眼球追踪仪和Windows Hello人脸 - 哔哩哔哩 (bilibili.com)](https://www.bilibili.com/read/cv7592036/)



### 补充：手势识别技术

[手势识别技术综述_Yellow.俊-CSDN博客_手势识别综述](https://blog.csdn.net/qq_39033834/article/details/92096496)



## 3.可以做的方向

手势识别？

眼动识别的改进：**手机端移植**、支持头部移动、更好的用户体验等

手机端移植：安卓系统、手机支架等

如何和OS课程联系的更加紧密一点？





## 4.可能有用的参考文献

- Krafka K, Khosla A, Kellnhofer P, et al. Eye tracking for everyone[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 2176-2184.
- 杨庆华, 张达磊, 荀一,等. 面向人机交互的眼动跟踪方法研究[J]. 机电工程, 2016, 33(7):904-908.
- Kassner M, Patera W, Bulling A. Pupil: an open source platform for pervasive eye tracking and mobile gaze-based interaction[C]//Proceedings of the 2014 ACM international joint conference on pervasive and ubiquitous computing: Adjunct publication. ACM, 2014: 1151-1160.
- Ernst J, Genc Y. Geometric calibration of head-worn multi-camera eye tracking system: U.S. Patent 8,957,948[P]. 2015-2-17.
- Mestre C, Gautier J, Pujol J. Robust eye tracking based on multiple corneal reflections for clinical applications[J]. Journal of biomedical optics, 2018, 23(3): 035001.
- Hansen D W. Eye gaze tracking: U.S. Patent 9,398,848[P]. 2016-7-26.